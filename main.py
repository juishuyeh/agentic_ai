"""
LangChain + LiteLLM Agent æœ€çµ‚ç‰ˆ
åŒ…å«æ¸…æ™°çš„å›æ‡‰æå–å’Œé¡¯ç¤º
"""
import json
import os
from dataclasses import dataclass

from langchain.agents import create_agent
from langchain.agents.structured_output import ToolStrategy
from langchain.tools import ToolRuntime, tool
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import InMemorySaver

# ===== é…ç½®å€ =====
LITELLM_BASE_URL = "http://localhost:4000"
LITELLM_API_KEY = os.getenv("LITELLM_API_KEY", "your_litellm_api_key")
MODEL_NAME = "gemma-3-12b"

# ===== ç³»çµ±æç¤ºè© =====
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å¤©æ°£åŠ©æ‰‹ã€‚

ä½ å¯ä»¥ä½¿ç”¨å…©å€‹å·¥å…·:
- get_weather_for_location: ç”¨æ–¼ç²å–ç‰¹å®šåŸå¸‚çš„å¤©æ°£
- get_user_location: ç”¨æ–¼ç²å–ä½¿ç”¨è€…çš„ä½ç½®

è«‹ç”¨ç¹é«”ä¸­æ–‡å›è¦†ï¼Œæ…‹åº¦å‹å–„å°ˆæ¥­ã€‚

IMPORTANT: åªå›ç­”å¤©æ°£ç›¸é—œçš„å•é¡Œã€‚å¦‚æœä½¿ç”¨è€…å•ä½ å…¶ä»–å•é¡Œï¼Œè«‹ç¦®è²Œåœ°å‘Šè¨´ä»–å€‘ä½ åªèƒ½å›ç­”å¤©æ°£ç›¸é—œçš„å•é¡Œã€‚

"""

# ===== ä¸Šä¸‹æ–‡çµæ§‹ =====
@dataclass
class Context:
    """åŸ·è¡Œæ™‚æœŸä¸Šä¸‹æ–‡"""
    user_id: str

# ===== å·¥å…·å®šç¾© =====
@tool
def get_weather_for_location(city: str) -> str:
    """ç²å–æŒ‡å®šåŸå¸‚çš„å¤©æ°£ã€‚"""
    # é€™è£¡å¯ä»¥ä¸²æ¥çœŸå¯¦çš„å¤©æ°£ API
    weather_data = {
        "å°åŒ—": "æ™´å¤©ï¼Œ25Â°Cï¼Œæ¿•åº¦ 60%",
        "å°å—": "å¤šé›²ï¼Œ28Â°Cï¼Œæ¿•åº¦ 70%",
        "é«˜é›„": "æ™´å¤©ï¼Œ30Â°Cï¼Œæ¿•åº¦ 65%",
    }
    return weather_data.get(city, f"{city} å¤©æ°£æ™´æœ—ï¼Œæº«åº¦é©ä¸­")

@tool
def get_user_location(runtime: ToolRuntime[Context]) -> str:
    """æ ¹æ“šä½¿ç”¨è€… ID æª¢ç´¢ä½¿ç”¨è€…ä½ç½®ã€‚"""
    # é€™è£¡å¯ä»¥å¾è³‡æ–™åº«æŸ¥è©¢ä½¿ç”¨è€…ä½ç½®
    user_locations = {
        "1": "å°åŒ—",
        "2": "å°å—",
        "3": "é«˜é›„",
    }
    user_id = runtime.context.user_id
    return user_locations.get(user_id, "å°åŒ—")

# ===== å›æ‡‰æ ¼å¼ =====
@dataclass
class WeatherResponse:
    """å¤©æ°£å›æ‡‰æ ¼å¼"""
    answer: str  # ä¸»è¦å›ç­”
    weather_info: str | None = None  # å¤©æ°£è³‡è¨Šï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰


model = ChatOpenAI(
    base_url=LITELLM_BASE_URL,
    api_key=LITELLM_API_KEY,
    model=MODEL_NAME,
    temperature=0.7,
)

# ===== å»ºç«‹ Agent =====
print("ğŸ¤– å»ºç«‹ Agent...")
checkpointer = InMemorySaver()

agent = create_agent(
    model=model,
    system_prompt=SYSTEM_PROMPT,
    tools=[get_user_location, get_weather_for_location],
    context_schema=Context,
    response_format=ToolStrategy(WeatherResponse),
    checkpointer=checkpointer
)

# ===== è¼”åŠ©å‡½æ•¸ =====
def extract_response(response: dict) -> str:
    """å¾ Agent å›æ‡‰ä¸­æå–æœ€çµ‚ç­”æ¡ˆ"""
    if 'messages' not in response:
        return str(response)
    
    # å–å¾—æœ€å¾Œä¸€æ¢ AI è¨Šæ¯
    messages = response['messages']
    for msg in reversed(messages):
        if hasattr(msg, 'content') and msg.content:
            content = msg.content.strip()
            # å¦‚æœæ˜¯çµæ§‹åŒ–å›æ‡‰æ ¼å¼
            if content.startswith('[ResponseFormat]'):
                try:
                    # æå– JSON éƒ¨åˆ†
                    json_str = content.split('[ResponseFormat]\n')[1].split('\n[END_ResponseFormat]')[0]
                    data = json.loads(json_str)
                    return data.get('answer', content)
                except Exception:
                    pass
            # ä¸€èˆ¬å›æ‡‰
            if content and not content.startswith('[') and content != '':
                return content
    
    return "æŠ±æ­‰ï¼Œç„¡æ³•ç”Ÿæˆå›æ‡‰"

def chat(user_message: str, config: dict, context: Context) -> str:
    """åŸ·è¡Œå°è©±ä¸¦è¿”å›å›æ‡‰"""
    response = agent.invoke(
        {"messages": [{"role": "user", "content": user_message}]},
        config=config,
        context=context
    )
    return extract_response(response)

# ===== ä¸»ç¨‹å¼ =====
if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸŒ¤ï¸  LangChain + LiteLLM å¤©æ°£åŠ©æ‰‹")
    print("="*60 + "\n")
    
    # å°è©±è¨­å®š
    user_id = "1"  # ä½¿ç”¨è€… ID
    thread_id = "weather-chat-001"  # å°è©± ID
    config = {"configurable": {"thread_id": thread_id}}
    context = Context(user_id=user_id)
    
    # äº’å‹•æ¨¡å¼
    print("\nğŸ’¬ é€²å…¥äº’å‹•æ¨¡å¼ï¼ˆè¼¸å…¥ 'exit' çµæŸï¼‰\n")
    
    while True:
        try:
            user_input = input("ğŸ‘¤ ä½ : ").strip()
            if user_input.lower() in ['exit', 'quit', 'çµæŸ', 'é›¢é–‹']:
                print("\nğŸ‘‹ å†è¦‹ï¼")
                break
            
            if not user_input:
                continue
            
            response_text = chat(user_input, config, context)
            print(f"ğŸ¤– åŠ©æ‰‹: {response_text}\n")
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è¦‹ï¼")
            break
        except Exception as e:
            print(f"âŒ éŒ¯èª¤: {e}\n")