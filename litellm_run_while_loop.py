import json
from dataclasses import dataclass

from dotenv import load_dotenv
from langchain.agents import create_agent
from langchain.agents.structured_output import ToolStrategy
from langchain.chat_models import init_chat_model
from langchain.tools import ToolRuntime, tool
from langgraph.checkpoint.memory import InMemorySaver
from prompt_toolkit import prompt
from prompt_toolkit.history import InMemoryHistory
from prompt_toolkit.styles import Style
from rich.console import Console

# ===== é…ç½®å€ =====
load_dotenv()
MODEL_NAME = "openai:gpt-oss-20b-local"

# ===== ç³»çµ±æç¤ºè© =====
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½æœ‰ç”¨çš„åŠ©æ‰‹ã€‚

ä½ å¯ä»¥ä½¿ç”¨å…©å€‹å·¥å…·:
- get_weather_for_location: ç”¨æ–¼ç²å–ç‰¹å®šåŸå¸‚çš„å¤©æ°£
- get_user_location: ç”¨æ–¼ç²å–ä½¿ç”¨è€…çš„ä½ç½®

è«‹ç”¨ç¹é«”ä¸­æ–‡å›è¦†ï¼Œæ…‹åº¦å‹å–„å°ˆæ¥­ã€‚"""

# ===== ä¸Šä¸‹æ–‡çµæ§‹ =====
@dataclass
class Context:
    """åŸ·è¡Œæ™‚æœŸä¸Šä¸‹æ–‡"""
    user_id: str

# ===== å·¥å…·å®šç¾© =====
@tool
def get_weather_for_location(city: str) -> str:
    """ç²å–æŒ‡å®šåŸå¸‚çš„å¤©æ°£ã€‚"""
    # é€™è£¡å¯ä»¥ä¸²æ¥çœŸå¯¦çš„å¤©æ°£ API
    weather_data = {
        "å°åŒ—": "æ™´å¤©ï¼Œ25Â°Cï¼Œæ¿•åº¦ 60%",
        "å°å—": "å¤šé›²ï¼Œ28Â°Cï¼Œæ¿•åº¦ 70%",
        "é«˜é›„": "æ™´å¤©ï¼Œ30Â°Cï¼Œæ¿•åº¦ 65%",
    }
    return weather_data.get(city, f"{city} å¤©æ°£æ™´æœ—ï¼Œæº«åº¦é©ä¸­")

@tool
def get_user_location(runtime: ToolRuntime[Context]) -> str:
    """æ ¹æ“šä½¿ç”¨è€… ID æª¢ç´¢ä½¿ç”¨è€…ä½ç½®ã€‚"""
    # é€™è£¡å¯ä»¥å¾è³‡æ–™åº«æŸ¥è©¢ä½¿ç”¨è€…ä½ç½®
    user_locations = {
        "1": "å°åŒ—",
        "2": "å°å—",
        "3": "é«˜é›„",
    }
    user_id = runtime.context.user_id
    return user_locations.get(user_id, "å°åŒ—")

# ===== å›æ‡‰æ ¼å¼ =====
@dataclass
class WeatherResponse:
    """å¤©æ°£å›æ‡‰æ ¼å¼"""
    answer: str  # ä¸»è¦å›ç­”
    weather_info: str | None = None  # å¤©æ°£è³‡è¨Šï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰

# ===== åˆå§‹åŒ–æ¨¡å‹ =====
print("ğŸ”§ åˆå§‹åŒ– LiteLLM æ¨¡å‹...")
model = init_chat_model(
    MODEL_NAME,
    temperature=1.0,
    max_tokens=2048
)

# ===== å»ºç«‹ Agent =====
print("ğŸ¤– å»ºç«‹ Agent...")
checkpointer = InMemorySaver()

agent = create_agent(
    model=model,
    system_prompt=SYSTEM_PROMPT,
    tools=[get_user_location, get_weather_for_location],
    context_schema=Context,
    response_format=ToolStrategy(WeatherResponse),
    checkpointer=checkpointer
)

# ===== è¼”åŠ©å‡½æ•¸ =====
def extract_response(response: dict) -> str:
    """å¾ Agent å›æ‡‰ä¸­æå–æœ€çµ‚ç­”æ¡ˆ"""
    if 'messages' not in response:
        return str(response)
    
    # å–å¾—æœ€å¾Œä¸€æ¢ AI è¨Šæ¯
    messages = response['messages']
    for msg in reversed(messages):
        if hasattr(msg, 'content') and msg.content:
            content = msg.content.strip()
            # å¦‚æœæ˜¯çµæ§‹åŒ–å›æ‡‰æ ¼å¼
            if content.startswith('[ResponseFormat]'):
                try:
                    # æå– JSON éƒ¨åˆ†
                    json_str = content.split('[ResponseFormat]\n')[1].split('\n[END_ResponseFormat]')[0]
                    data = json.loads(json_str)
                    return data.get('answer', content)
                except Exception:
                    pass
            # ä¸€èˆ¬å›æ‡‰
            if content and not content.startswith('[') and content != '':
                return content
    
    return "æŠ±æ­‰ï¼Œç„¡æ³•ç”Ÿæˆå›æ‡‰"

def chat(user_message: str, config: dict, context: Context) -> str:
    """åŸ·è¡Œå°è©±ä¸¦è¿”å›å›æ‡‰"""
    response = agent.invoke(
        {"messages": [{"role": "user", "content": user_message}]},
        config=config,
        context=context
    )
    return extract_response(response)

# ===== ä¸»ç¨‹å¼ =====
if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸŒ¤ï¸  LangChain + LiteLLM å¤©æ°£åŠ©æ‰‹")
    print("="*60 + "\n")
    
    # å°è©±è¨­å®š
    user_id = "1"  # ä½¿ç”¨è€… ID
    thread_id = "weather-chat-001"  # å°è©± ID
    config = {"configurable": {"thread_id": thread_id}}
    context = Context(user_id=user_id)
    
    # äº’å‹•æ¨¡å¼
    print("\nğŸ’¬ é€²å…¥äº’å‹•æ¨¡å¼ï¼ˆè¼¸å…¥ 'exit' çµæŸï¼‰\n")
    
    # while True:
    #     try:
    #         user_input = prompt("ğŸ‘¤ ä½ : ").strip()
    #         if user_input.lower() in ['exit', 'quit', 'çµæŸ', 'é›¢é–‹']:
    #             print("\nğŸ‘‹ å†è¦‹ï¼")
    #             break
    #         if not user_input:
    #             continue
    #         response_text = chat(user_input, config, context)
    #         print(f"ğŸ¤– åŠ©æ‰‹: {response_text}\n")
    #     except KeyboardInterrupt:
    #         print("\n\nğŸ‘‹ å†è¦‹ï¼")
    #         break
    #     except Exception as e:
    #         print(f"âŒ éŒ¯èª¤: {e}\n")


    # è¨­å®šæ¨£å¼
    input_style = Style.from_dict({
        'prompt': 'cyan bold',
    })

    console = Console()
    history = InMemoryHistory()

    def get_user_input() -> str:
        """å–å¾—ä½¿ç”¨è€…è¼¸å…¥"""
        return prompt(
            [('class:prompt', 'ğŸ‘¤ ä½ : ')],
            style=input_style,
            history=history,
            mouse_support=True,
        ).strip()

    def display_response(text: str):
        """é¡¯ç¤ºåŠ©æ‰‹å›æ‡‰"""
        console.print(f"[bold green]ğŸ¤– åŠ©æ‰‹:[/bold green] {text}\n")

    while True:
        try:
            user_input = get_user_input()
            if user_input.lower() in ['exit', 'quit', 'çµæŸ', 'é›¢é–‹']:
                console.print("[yellow]ğŸ‘‹ å†è¦‹![/yellow]")
                break
            
            if not user_input:
                continue
            
            response_text = chat(user_input, config, context)
            display_response(response_text)

        except KeyboardInterrupt:
            console.print("\n[yellow]ğŸ‘‹ å†è¦‹![/yellow]")
            break
        except Exception as e:
            console.print(f"[red]âŒ éŒ¯èª¤: {e}[/red]\n")